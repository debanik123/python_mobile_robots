{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71655c7d-abf6-4a9b-9f21-d49bc4d09d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211e3df8-bedd-463c-ab75-61fff2b77f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(np.random.randint(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6476fa65-d704-4eb4-ac25-3ff249c769e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bdfddd7-f899-463e-b732-edb21ef5695c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9285d79f-30ee-4fc5-9107-f4cdb31c21a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(5000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f2b601-e468-4661-812f-494b4986ca99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00871851, 0.34147093, 0.33737929, 0.95904576, 0.19182944])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0990c3-d176-4afd-9642-a435da17f4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d131e1c-60df-4d9b-b47a-1a8416590e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(np.random.random((3,2)))\n",
    "b = np.array(np.random.random((1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96905265-0656-4c3c-9520-e0542f54c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52743566],\n",
       "       [0.00375175],\n",
       "       [0.19339318]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c95bbf-4e37-4bd1-afef-b5687b137df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3949987783927168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.std(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1789642-6b0d-4853-babb-00b3f32ec210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0812eeeb-6d92-49c0-b3f6-b15d84d1f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa883dce-1fad-4e1a-8638-e53e873bb8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a378c8a-a53e-4bcc-8ab4-255a66cd0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846f82b6-99be-4e4e-82ca-557387c21d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 8s 1us/step\n",
      "11501568/11490434 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692c49d8-0902-4c4e-b4ef-85a4afed9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([Flatten(input_shape=(28,28)),\n",
    "                           Dense(1024, activation=tf.nn.leaky_relu),\n",
    "                           Dropout(0.3),\n",
    "                           Dense(512, activation=tf.nn.leaky_relu),\n",
    "                           Dropout(0.2),\n",
    "                           Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56bd04e-3251-42d0-b94c-fe9332348dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58e01c3-db30-4f79-b5ce-a739c10f9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:21:00.473854: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2022-04-08 23:21:00.802514: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 21s 2ms/step - loss: 0.2467 - accuracy: 0.9254\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9535\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1399 - accuracy: 0.9600\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1304 - accuracy: 0.9640\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1262 - accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48a10c69a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e9fe560-5b31-4241-8a75-fc582943c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:21:38.092453: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.\n",
      "2022-04-08 23:21:38.135414: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11502323299646378, 0.9718000292778015]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "331d0dc0-446f-4318-b9eb-81a51f3650a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = tf.keras.Input(shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7431b333-4d6e-4cf1-b37f-ac1a48ed5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(ip)\n",
    "x = Dense(1024, activation=tf.nn.leaky_relu)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation=tf.nn.leaky_relu)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation=tf.nn.softmax)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f189d04f-2aa9-445e-b2f0-59426c1277d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=ip, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "026c3925-0d2c-486d-b3d7-824cc8fd5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              803840    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,333,770\n",
      "Trainable params: 1,333,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8858b8f1-b3d1-4a64-b914-0e8d954cbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37215967-452f-45d8-9513-db581e5f4e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:21:49.700303: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2511 - accuracy: 0.9233\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1587 - accuracy: 0.9531\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9597\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1307 - accuracy: 0.9636\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1262 - accuracy: 0.9658\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1181 - accuracy: 0.9684\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1165 - accuracy: 0.9690\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1137 - accuracy: 0.9704\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1140 - accuracy: 0.9708\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9728\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1088 - accuracy: 0.9741\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1153 - accuracy: 0.9741\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1142 - accuracy: 0.9742\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1070 - accuracy: 0.9766\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9767\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1105 - accuracy: 0.9778\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1122 - accuracy: 0.9768\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1096 - accuracy: 0.9783\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1154 - accuracy: 0.9783\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1092 - accuracy: 0.9796\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1162 - accuracy: 0.9800\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1155 - accuracy: 0.9800\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1105 - accuracy: 0.9808\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1181 - accuracy: 0.9802\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1201 - accuracy: 0.9810\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1241 - accuracy: 0.9809\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1238 - accuracy: 0.9813\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1198 - accuracy: 0.9826\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1299 - accuracy: 0.9819\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1264 - accuracy: 0.9826\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1245 - accuracy: 0.9827\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1325 - accuracy: 0.9834\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1207 - accuracy: 0.9844\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1276 - accuracy: 0.9842\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1344 - accuracy: 0.9837\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1356 - accuracy: 0.9841\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1346 - accuracy: 0.9843\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1310 - accuracy: 0.9849\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1396 - accuracy: 0.9841\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1409 - accuracy: 0.9849\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1382 - accuracy: 0.9854\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1388 - accuracy: 0.9855\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1448 - accuracy: 0.9849\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1474 - accuracy: 0.9858\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1440 - accuracy: 0.9864\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1458 - accuracy: 0.9861\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1446 - accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1523 - accuracy: 0.9865\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1524 - accuracy: 0.9865\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1450 - accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4884135250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d42b137-d875-4893-a4c6-f83be9bf33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e8e9586-a028-4b24-9ed6-65c677dcca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    cv2.imshow(\"imu\", x_train[i])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e531477e-2937-4b4c-b9be-8f68592dc090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2987923-4df5-4e0e-9474-3fe227bcba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 4s 0us/step\n",
      "9420800/9406464 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.MobileNetV2(input_shape=((32,32,3)),\n",
    "                                          include_top=False,\n",
    "                                          weights=\"imagenet\",\n",
    "                                          pooling=\"avg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7f775fd-688e-46cc-a592-039eedb40563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1867db-05e1-41c5-a51f-15d95b5fd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([Conv2D(28,(3,3), activation=tf.nn.leaky_relu, input_shape=(28,28,1)),\n",
    "                           MaxPooling2D((2,2)),\n",
    "                           Conv2D(56,(3,3), activation=tf.nn.leaky_relu),\n",
    "                           MaxPooling2D((2,2)),\n",
    "                           Conv2D(112,(3,3), activation=tf.nn.leaky_relu),\n",
    "                           Flatten(),\n",
    "                           Dense(1024, activation=tf.nn.leaky_relu),\n",
    "                           Dropout(0.3),\n",
    "                           Dense(512, activation=tf.nn.leaky_relu),\n",
    "                           Dropout(0.2),\n",
    "                           Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc75cf9-c19f-4f2f-9e84-081d5efa504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 28)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 56)        14168     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 56)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 112)         56560     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1008)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              1033216   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,634,154\n",
      "Trainable params: 1,634,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "451567a1-2a16-45d1-959c-4560cd361388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a628dbbc-2650-4b8b-b7ff-05890217ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:32:10.841851: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 69s 26ms/step - loss: 0.1232 - accuracy: 0.9623 - val_loss: 0.0461 - val_accuracy: 0.9858\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.0461 - accuracy: 0.9855 - val_loss: 0.0376 - val_accuracy: 0.9882\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.0593 - val_accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.0481 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0420 - val_accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.0545 - val_accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0312 - accuracy: 0.9912 - val_loss: 0.0459 - val_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0325 - accuracy: 0.9914 - val_loss: 0.0568 - val_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.0493 - val_accuracy: 0.9892\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7434bc4-fde6-4bff-b55a-4ec567805564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f96fb991-ccb5-4c55-927a-bd0dae081cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f43da15d-daee-4497-992b-a984d4130821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3e0eb33-ff0b-4cd1-9ee6-2fc7cb75b697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db410def-63e1-47c3-8b34-aff773fa8a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 28, 28, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:44:53.217628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 3)\n",
      "(60000, 32, 32, 3) (60000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:44:54.047230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:54.047696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:54.068689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-08 23:44:54.109438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:54.109726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:54.109892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:59.492380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:59.493068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:59.493730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-08 23:44:59.494306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5148 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-04-08 23:44:59.541073: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1128960000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "mnist = datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "# expand new axis, channel axis \n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "print(x_train.shape)\n",
    "\n",
    "# [optional]: we may need 3 channel (instead of 1)\n",
    "x_train = np.repeat(x_train, 3, axis=-1)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = tf.image.resize(x_train, [32,32]) # if we want to resize\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97489f23-12e1-4364-a4a3-05980a41281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 41s 0us/step\n",
      "94781440/94765736 [==============================] - 41s 0us/step\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.ResNet50(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e76eefd-520f-4be2-b4b2-1b2797b3fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77285e74-3bd6-4844-a856-e8a66c5de864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b073655-0de3-4d95-ba72-73aa2d4bd2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 23:45:57.662777: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n",
      "2022-04-08 23:46:03.401349: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 464s 944ms/step - loss: 0.1244 - accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d08150a-41ec-43c6-ad66-75705d306fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 6s 1us/step\n",
      "9420800/9406464 [==============================] - 6s 1us/step\n",
      "469/469 [==============================] - 24s 41ms/step - loss: 0.1978 - accuracy: 0.9438\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.MobileNetV2(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc28998-fc07-49a4-a927-a7aebfa78827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 10s 1us/step\n",
      "16719872/16705208 [==============================] - 10s 1us/step\n",
      "469/469 [==============================] - 83s 161ms/step - loss: 0.1878 - accuracy: 0.9429\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.EfficientNetB0(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773c08cd-c636-4798-b8dd-dea9c72b498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 60s 1us/step\n",
      "80150528/80134624 [==============================] - 60s 1us/step\n",
      "469/469 [==============================] - 142s 299ms/step - loss: 0.8332 - accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.VGG19(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d76a23-00de-4a19-af21-4831c1affe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 72s 1us/step\n",
      "94683136/94668760 [==============================] - 72s 1us/step\n",
      "469/469 [==============================] - 111s 226ms/step - loss: 0.1756 - accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.ResNet50V2(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04882a0-843b-4906-baae-765e1ac35748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
      "12689408/12683000 [==============================] - 9s 1us/step\n",
      "12697600/12683000 [==============================] - 9s 1us/step\n",
      "469/469 [==============================] - 23s 38ms/step - loss: 0.2213 - accuracy: 0.9354\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.MobileNetV3Large(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda4f435-52b3-4485-9001-bf14887ff8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "4341760/4334752 [==============================] - 3s 1us/step\n",
      "4349952/4334752 [==============================] - 3s 1us/step\n",
      "469/469 [==============================] - 16s 23ms/step - loss: 0.4637 - accuracy: 0.8607\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.MobileNetV3Small(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0387684a-b54d-40e3-a832-8251ddff13b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 10s 1us/step\n",
      "17235968/17225924 [==============================] - 10s 1us/step\n",
      "469/469 [==============================] - 53s 108ms/step - loss: 0.1646 - accuracy: 0.9551\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.MobileNet(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "248c78ba-4586-4b69-b98a-2dd70d6b4e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24281088/24274472 [==============================] - 20s 1us/step\n",
      "24289280/24274472 [==============================] - 20s 1us/step\n",
      "469/469 [==============================] - 70s 131ms/step - loss: 0.1665 - accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "ip = tf.keras.Input(shape=(32,32,3))\n",
    "net = tf.keras.applications.EfficientNetV2B0(input_tensor = ip,\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(net.output)\n",
    "op = Dense(10, activation=tf.nn.softmax, use_bias=True)(gap)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=net.input, outputs=op)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "his = model.fit(x_train, y_train, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83e851-0bc2-4537-8bac-b5b285bc8a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
